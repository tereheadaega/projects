{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "397c92e3",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "-------------------\n",
    "\n",
    "Будет очень хорошо, если ты будешь помечать свои действия следующим образом:\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Комментарий студента:</b> ...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Были внесены следующие изменения ...\n",
    "</div>\n",
    "\n",
    "<font color='green'><b>Полезные (и просто интересные) материалы:</b></font> \\\n",
    "Для работы с текстами используют и другие подходы. Например, сейчас активно используются RNN (LSTM) и трансформеры (BERT и другие с улицы Сезам, например, ELMO). НО! Они не являются панацеей, не всегда они нужны, так как и TF-IDF или Word2Vec + модели из классического ML тоже могут справляться. \\\n",
    "BERT тяжелый, существует много его вариаций для разных задач, есть готовые модели, есть надстройки над библиотекой transformers. Если, обучать BERT на GPU (можно в Google Colab или Kaggle), то должно быть побыстрее.\\\n",
    "https://huggingface.co/transformers/model_doc/bert.html \\\n",
    "https://t.me/renat_alimbekov \\\n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - Про LSTM \\\n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - про энкодер-декодер модели, этеншены\\\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - официальный гайд\n",
    "по трансформеру от создателей pytorch\\\n",
    "https://transformer.huggingface.co/ - поболтать с трансформером \\\n",
    "Библиотеки: allennlp, fairseq, transformers, tensorflow-text — множествореализованных\n",
    "методов для трансформеров методов NLP \\\n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html \n",
    "\n",
    "<font color='green'>Пример BERT с GPU:\n",
    "```python\n",
    "%%time\n",
    "from tqdm import notebook\n",
    "batch_size = 2 # для примера возьмем такой батч, где будет всего две строки датасета\n",
    "embeddings = [] \n",
    "for i in notebook.tqdm(range(input_ids.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(input_ids[batch_size*i:batch_size*(i+1)]).cuda() # закидываем тензор на GPU\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.cuda()\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy()) # перевод обратно на проц, чтобы в нумпай кинуть\n",
    "        del batch\n",
    "        del attention_mask_batch\n",
    "        del batch_embeddings\n",
    "        \n",
    "features = np.concatenate(embeddings) \n",
    "```\n",
    "Можно сделать предварительную проверку на наличие GPU.\\\n",
    "Например, так: ```device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")```\\\n",
    "Тогда вместо .cuda() нужно писать .to(device)\n",
    "\n",
    "Если понравилась работа с текстами, то можешь посмотреть очень интересный (но очень-очень сложный) курс лекций: https://github.com/yandexdataschool/nlp_course .\n",
    "</font>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект может быть зачтен, но я его отправлю назад, чтобы у тебя была возможность задать вопросы и внести правки, при желании. Однако, ты можешь просто вернуть проект в таком же виде и я его зачту."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874eb19b",
   "metadata": {},
   "source": [
    "## Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d1401",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис.\n",
    "\n",
    "Пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. \n",
    "\n",
    "Необходимо разработать инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Задача: обучить модель классификации комментариев на позитивные и негативные.\n",
    "\n",
    "Цель: \n",
    "Построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec2cdb",
   "metadata": {},
   "source": [
    "# Шаг. Изучить общую информацию и подготовить данные к исследованию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "120250fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a4dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "\n",
    "\n",
    "from tqdm import notebook \n",
    "\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "RND = 190103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046631b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что все импорты собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f14e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maksimkeller/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/maksimkeller/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccdd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = 'toxic_comments.csv'\n",
    "pth2 = '/datasets/toxic_comments.csv'\n",
    "if os.path.exists(pth1):\n",
    "    df = pd.read_csv(pth1)\n",
    "elif os.path.exists(pth2):\n",
    "    df = pd.read_csv(pth2)\n",
    "else:\n",
    "    print(\"Проверьте правильность пути к датасету\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12fa9cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138374</th>\n",
       "      <td>\"\\n\\nRather than delete the  tag, could you ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "138374  \"\\n\\nRather than delete the  tag, could you ad...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры полученного датафрейма: (159571, 2) \n",
      "\n",
      "Изучим количество токсичных (1) и не токсичных (0) комментариев:\n",
      "0    143346\n",
      "1     16225\n",
      "Name: toxic, dtype: int64 \n",
      "\n",
      "Пример токсичного комментария 6    COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "Name: text, dtype: object \n",
      "\n",
      "Пример не токсичного комментария 0    Explanation\\nWhy the edits made under my usern...\n",
      "Name: text, dtype: object \n",
      "\n",
      "Количество символов в самом длинном тексте:  5000\n",
      "Количество символов в самом коротком тексте:  6\n"
     ]
    }
   ],
   "source": [
    "display(df.sample())\n",
    "print('Размеры полученного датафрейма:',df.shape, '\\n')\n",
    "\n",
    "print('Изучим количество токсичных (1) и не токсичных (0) комментариев:')\n",
    "print(df['toxic'].value_counts(), '\\n')\n",
    "print('Пример токсичного комментария',df.loc[df['toxic']==1,'text'].head(1), '\\n')\n",
    "print('Пример не токсичного комментария',df.loc[df['toxic']==0,'text'].head(1), '\\n')\n",
    "print('Количество символов в самом длинном тексте: ', max(map(len, df['text'])))\n",
    "print('Количество символов в самом коротком тексте: ', min(map(len, df['text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6fc1e7",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Полученные данные содержат около 160 тыс. комментариев на английском языке. Количество токсичных комментариев значительно в имеющейся выборке значительно меньше. Длинна комментариев варьируется от 6 до 5000 до символов.\n",
    "\n",
    "Для дальнейшей работы все комментарии необходимо лемматизировать и привести к векторному виду."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f392132",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корреткно. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0da8d",
   "metadata": {},
   "source": [
    "# Шаг. Построение моделей\n",
    "\n",
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1927d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(1000, random_state= RND).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609237b",
   "metadata": {},
   "source": [
    "Объём предоставленного датасета настолько велик, что работа с полным массивом данных потребует больших ресурсов, недоступных в рамках данного исследования. Поэтому, для дальнейшей работы будет выделен сэмпл из 100 тысяч комментариев, что позволит сэкономить ресурсы, при этом получив результат, удовлетворяющий начальным требованиям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78685d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Изучим количество токсичных (1) и не токсичных (0) комментариев:\n",
      "0    89872\n",
      "1    10128\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Изучим количество токсичных (1) и не токсичных (0) комментариев:')\n",
    "print(df['toxic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83376a",
   "metadata": {},
   "source": [
    "Заметим, что в полученном сэмпле также присутствует дисбаланс классов, поэтому далее будет проведена работа по установке баланса классов. Однако, ранее необходимо очистить текст от символов, слов состоящих из одной буквы и лемматизировать слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "212dd8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_and_lemmatize(df,text):\n",
    "    '''Функция проводит очистку анализируемого текста и создает корпус'''\n",
    "\n",
    "    corpus = df['text'].apply(lambda x: \" \".join((re.sub(r'[^a-zA-Z ]', ' ', x)).split()))\n",
    "    # Уберём слова из одной буквы\n",
    "    corpus = df['text'].apply(lambda x: \" \".join((re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x)).split()))\n",
    "    m = WordNetLemmatizer()\n",
    "    lemm_list = corpus.apply(lambda x: [m.lemmatize(w,'n') for w in nltk.word_tokenize(x)])\n",
    "    lemm_text = lemm_list.apply(lambda text:' '.join(text))\n",
    "\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0baa9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized = clear_and_lemmatize(df,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14046dca",
   "metadata": {},
   "source": [
    "Далее разделим выборку на целевой и общие признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5cdcdf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка и лемматизация были сделаны верно, молодец!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcdbf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = lemmatized # извлечём признаки\n",
    "target = df['toxic'] # извлечём целевой признак"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf4000",
   "metadata": {},
   "source": [
    "Разделим данные на три группы: train, valid и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62d1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, train_size=0.60,random_state= RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c58062",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test, features_valid, target_test, target_valid = train_test_split(\n",
    "    features_test, target_test, train_size=0.50,random_state= RND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e0720d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "600\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(len(features_train))\n",
    "print(len(features_valid))\n",
    "print(len(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f05d5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c15020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 88.5%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/_prrccxj0n139bry1p6r136h0000gn/T/ipykernel_45894/397348363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\naccuracy: {}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe_lr = Pipeline([('vect', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('model', LogisticRegression())])\n",
    "model = pipe_lr.fit(features_train, target_train)\n",
    "prediction = model.predict(features_test)\n",
    "print('\\n accuracy: {}%'.format(round(accuracy_score(target_test, prediction)*100,2)))\n",
    "print('\\n',confusion_matrix(target_test, prediction))\n",
    "print('\\n',classification_report(target_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b52e36",
   "metadata": {},
   "source": [
    "Удостоверившись в корректности разбиения, проведём upsampling и downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bceb68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features,target,repeat):\n",
    "    features_zeros = features[target_train == 0]\n",
    "    features_ones = features[target_train == 1]\n",
    "    target_zeros = target[target_train == 0]\n",
    "    target_ones = target[target_train == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state = RND)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd22767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_upsampled, target_train_upsampled = upsample(features_train, target_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca6bb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state= RND)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state= RND)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state= RND)\n",
    "\n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccae40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_downsampled, target_train_downsampled = downsample(features_train, target_train, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24931bad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Верно, что баланс классоа был изменен только в треине.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c52435",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "vect_up = CountVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "vect_down = CountVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "\n",
    "\n",
    "vect_train_cv = vect.fit_transform(features_train)\n",
    "vect_train_cv_upsampled = vect_up.fit_transform(features_train_upsampled)\n",
    "vect_train_cv_downsampled = vect_down.fit_transform(features_train_downsampled)\n",
    "\n",
    "\n",
    "vect_valid_cv = vect.transform(features_valid)\n",
    "vect_valid_cv_up = vect_up.transform(features_valid)\n",
    "vect_valid_cv_down = vect_down.transform(features_valid)\n",
    "\n",
    "\n",
    "vect_test_cv = vect.transform(features_test)\n",
    "vect_test_cv_up = vect_up.transform(features_test)\n",
    "vect_test_cv_down = vect_down.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f7d917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "vect_up = TfidfVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "vect_down = TfidfVectorizer(stop_words=stopwords,dtype=np.float32)\n",
    "\n",
    "vect_train_tfidf = vect.fit_transform(features_train)\n",
    "vect_train_tfidf_upsampled = vect_up.fit_transform(features_train_upsampled)\n",
    "vect_train_tfidf_downsampled = vect_down.fit_transform(features_train_downsampled)\n",
    "\n",
    "\n",
    "vect_valid_tfidf = vect.transform(features_valid)\n",
    "vect_valid_tfidf_up = vect_up.transform(features_valid)\n",
    "vect_valid_tfidf_down = vect_down.transform(features_valid)\n",
    "\n",
    "\n",
    "vect_test_tfidf = vect.transform(features_test)\n",
    "vect_test_tfidf_up = vect_up.transform(features_test)\n",
    "vect_test_tfidf_down = vect_down.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e168467",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_list = [\n",
    "    vect_train_cv,\n",
    "    vect_train_cv_upsampled,\n",
    "    vect_train_cv_downsampled,\n",
    "    vect_train_tfidf,\n",
    "    vect_train_tfidf_upsampled,\n",
    "    vect_train_tfidf_downsampled\n",
    "]\n",
    "\n",
    "target_train_list = [\n",
    "    target_train,\n",
    "    target_train_upsampled,\n",
    "    target_train_downsampled,\n",
    "    target_train,\n",
    "    target_train_upsampled,\n",
    "    target_train_downsampled\n",
    "]\n",
    "\n",
    "features_valid_list = [\n",
    "    vect_valid_cv,\n",
    "    vect_valid_cv_up,\n",
    "    vect_valid_cv_down,\n",
    "    vect_valid_tfidf,\n",
    "    vect_valid_tfidf_up,\n",
    "    vect_valid_tfidf_down\n",
    "    \n",
    "]\n",
    "\n",
    "features_test_list = [\n",
    "    vect_test_cv,\n",
    "    vect_test_cv_up,\n",
    "    vect_test_cv_down,\n",
    "    vect_test_tfidf,\n",
    "    vect_test_tfidf_up,\n",
    "    vect_test_tfidf_down\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d91bf2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано верно. Отлично, что векторизатор был обучен только на тренировочной части данных.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30d485a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerator(model):\n",
    "    '''Функция подбирает лучшее значение метрики качества для модели-аргумента среди шести наборов входных данных'''\n",
    "    score_best = 0\n",
    "    best_data = 0\n",
    "    i= 0\n",
    "    for X, y, z in zip(features_train_list, target_train_list, features_valid_list):\n",
    "        i+=1\n",
    "        model.fit(X,y)\n",
    "        pred = model.predict(z)\n",
    "        score = f1_score(target_valid, pred)\n",
    "        if score > score_best:\n",
    "            score_best = score\n",
    "            best_data = i\n",
    "            \n",
    "    print('f1 метрика: {0}'.format(round(score_best, 2)))\n",
    "    print('Индекс лучшего набора данных:', best_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585f18cd",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "\n",
    "Изучим значение метрики качества f1 логистической регрессии на дэфолтных настройках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6befdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.76\n",
      "Индекс лучшего набора данных: 2\n"
     ]
    }
   ],
   "source": [
    "model_log = LogisticRegression()\n",
    "enumerator(model_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4006eaf5",
   "metadata": {},
   "source": [
    "### Случайный лес\n",
    "\n",
    "Изучим значение метрики качества f1 случайного леса на дэфолтных настройках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bb7201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.69\n",
      "Индекс лучшего набора данных: 6\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier()\n",
    "enumerator(model_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7e4da2",
   "metadata": {},
   "source": [
    "### LGBMClassifier\n",
    "\n",
    "Изучим значение метрики качества f1 на дэфолтных настройках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cab69498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.74\n",
      "Индекс лучшего набора данных: 4\n"
     ]
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier()\n",
    "enumerator(model_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d048bd",
   "metadata": {},
   "source": [
    "### CatBoostClassifier\n",
    "\n",
    "Изучим значение метрики качества f1 на дэфолтных настройках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899d6e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.75\n",
      "Индекс лучшего набора данных: 6\n"
     ]
    }
   ],
   "source": [
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "enumerator(model_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617bc7d3",
   "metadata": {},
   "source": [
    "## Поиск наилучших параметров для лучшей модели\n",
    "\n",
    "По итогам рассмотрения 4 моделей, один из наилучших результатов показала модель CatBoostClassifier. Подберём гиперпараметры для выбранной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ae11f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_search(obj_func, n_trials):\n",
    "    '''Функция поиска наилучших гиперпараметров'''\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(obj_func, n_trials=n_trials)\n",
    "    \n",
    "    print(f\"\\tBest params:\")\n",
    "\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"\\t\\t{key}: {value}\")\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad7fe116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr(trial):\n",
    "    '''Функция поиска наилучших гиперпараметров для модели CatBoostClassifier'''\n",
    "    n_est = trial.suggest_int('n_estimators', 150, 500)\n",
    "    max_d = trial.suggest_int('max_depth', 3, 8)\n",
    "    learning_rate = trial.suggest_float('eta', .001 , .2, step= .025)\n",
    "    \n",
    "    model = CatBoostClassifier(n_estimators = n_est,max_depth = max_d, eta = learning_rate, verbose=False)\n",
    "    scores = cross_validate(model, vect_train_tfidf_upsampled, target_train_upsampled, cv=5, scoring='f1')\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48d908",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7025d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_check(model,\n",
    "                X = vect_train_tfidf_upsampled,\n",
    "                y = target_train_upsampled,\n",
    "                z = vect_valid_tfidf_up,\n",
    "                zt= target_valid):\n",
    "    '''Функция для проверки значения целевой метрики'''\n",
    "    model.fit(X,y)\n",
    "    pred = model.predict(z)\n",
    "    score = f1_score(zt, pred)\n",
    "    print('f1 метрика: {0}'.format(round(score, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9234530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-22 21:22:41,105]\u001b[0m A new study created in memory with name: no-name-87c1f79b-55dc-4f35-9522-9f8c3a7e243e\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 21:28:16,204]\u001b[0m Trial 0 finished with value: 0.8894494366809044 and parameters: {'n_estimators': 303, 'max_depth': 4, 'eta': 0.101}. Best is trial 0 with value: 0.8894494366809044.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 21:37:08,638]\u001b[0m Trial 1 finished with value: 0.8959983395484434 and parameters: {'n_estimators': 364, 'max_depth': 5, 'eta': 0.07600000000000001}. Best is trial 1 with value: 0.8959983395484434.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 21:52:30,221]\u001b[0m Trial 2 finished with value: 0.6149136414324745 and parameters: {'n_estimators': 393, 'max_depth': 6, 'eta': 0.001}. Best is trial 1 with value: 0.8959983395484434.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 22:22:58,923]\u001b[0m Trial 3 finished with value: 0.9425976025876759 and parameters: {'n_estimators': 287, 'max_depth': 7, 'eta': 0.176}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 23:02:47,294]\u001b[0m Trial 4 finished with value: 0.892477510013542 and parameters: {'n_estimators': 355, 'max_depth': 7, 'eta': 0.051000000000000004}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 23:05:53,510]\u001b[0m Trial 5 finished with value: 0.8090412563400868 and parameters: {'n_estimators': 167, 'max_depth': 3, 'eta': 0.051000000000000004}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 23:49:28,551]\u001b[0m Trial 6 finished with value: 0.9302862321716644 and parameters: {'n_estimators': 229, 'max_depth': 8, 'eta': 0.15100000000000002}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 23:54:10,261]\u001b[0m Trial 7 finished with value: 0.8595371204758061 and parameters: {'n_estimators': 265, 'max_depth': 5, 'eta': 0.051000000000000004}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-22 23:58:16,451]\u001b[0m Trial 8 finished with value: 0.8733917008960891 and parameters: {'n_estimators': 383, 'max_depth': 3, 'eta': 0.07600000000000001}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 00:02:52,732]\u001b[0m Trial 9 finished with value: 0.8821127618362574 and parameters: {'n_estimators': 449, 'max_depth': 3, 'eta': 0.07600000000000001}. Best is trial 3 with value: 0.9425976025876759.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 01:16:56,531]\u001b[0m Trial 10 finished with value: 0.9817893346120179 and parameters: {'n_estimators': 493, 'max_depth': 8, 'eta': 0.176}. Best is trial 10 with value: 0.9817893346120179.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 02:33:00,915]\u001b[0m Trial 11 finished with value: 0.9819637924736373 and parameters: {'n_estimators': 495, 'max_depth': 8, 'eta': 0.176}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 03:54:02,821]\u001b[0m Trial 12 finished with value: 0.9790169693648462 and parameters: {'n_estimators': 499, 'max_depth': 8, 'eta': 0.15100000000000002}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 04:29:16,478]\u001b[0m Trial 13 finished with value: 0.978538016984756 and parameters: {'n_estimators': 497, 'max_depth': 7, 'eta': 0.176}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 05:43:52,416]\u001b[0m Trial 14 finished with value: 0.960281051448513 and parameters: {'n_estimators': 437, 'max_depth': 8, 'eta': 0.126}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 05:55:36,856]\u001b[0m Trial 15 finished with value: 0.952468560451661 and parameters: {'n_estimators': 439, 'max_depth': 6, 'eta': 0.15100000000000002}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 06:29:03,508]\u001b[0m Trial 16 finished with value: 0.9553435607430897 and parameters: {'n_estimators': 461, 'max_depth': 7, 'eta': 0.126}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 07:40:53,091]\u001b[0m Trial 17 finished with value: 0.9779118106997338 and parameters: {'n_estimators': 413, 'max_depth': 8, 'eta': 0.176}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 07:54:44,834]\u001b[0m Trial 18 finished with value: 0.946046432261225 and parameters: {'n_estimators': 479, 'max_depth': 6, 'eta': 0.126}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/optuna/distributions.py:545: UserWarning: The distribution is specified by [0.001, 0.2] and q=0.025, but the range is not divisible by `q`. It will be replaced by [0.001, 0.176].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-06-23 09:02:42,721]\u001b[0m Trial 19 finished with value: 0.6534341468188577 and parameters: {'n_estimators': 324, 'max_depth': 8, 'eta': 0.001}. Best is trial 11 with value: 0.9819637924736373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest params:\n",
      "\t\tn_estimators: 495\n",
      "\t\tmax_depth: 8\n",
      "\t\teta: 0.176\n",
      "CPU times: user 1d 3h 17min 41s, sys: 17h 30min 9s, total: 1d 20h 47min 50s\n",
      "Wall time: 11h 40min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_study = optuna_search(objective_lr, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a452b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.75\n"
     ]
    }
   ],
   "source": [
    "score_check(CatBoostClassifier(n_estimators = 495,max_depth = 8, eta = .176, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e453482b",
   "metadata": {},
   "source": [
    "Ещё одной моделью, показавшей высокий результат стал LGBMClassifier. Проведём поиск наилучших гиперпараметров для это модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40ce6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lr_lgbm(trial):\n",
    "    n_leaves = trial.suggest_int('num_leaves', 25,55)\n",
    "    n_est = trial.suggest_int('n_estimators', 350,600, step = 10)\n",
    "    l_rate = trial.suggest_float('learning_rate', .05,.8, step= .05)\n",
    "    b_type = trial.suggest_categorical('boosting_type', ['gbdt','dart','goss','rf'])\n",
    "    \n",
    "    model = LGBMClassifier(num_leaves = n_leaves, n_estimators = n_est, learning_rate = l_rate, boosting_type = b_type)\n",
    "    scores = cross_validate(model, vect_train_tfidf_downsampled, target_train_downsampled, cv=5, scoring='f1')\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2459cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-22 18:10:56,330]\u001b[0m A new study created in memory with name: no-name-cf830c16-b876-43c4-9144-bde27f9b3066\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:13:19,174]\u001b[0m Trial 0 finished with value: 0.9812262568855198 and parameters: {'num_leaves': 44, 'n_estimators': 370, 'learning_rate': 0.3, 'boosting_type': 'goss'}. Best is trial 0 with value: 0.9812262568855198.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:14:33,511]\u001b[0m Trial 1 finished with value: 0.9858651252315414 and parameters: {'num_leaves': 45, 'n_estimators': 540, 'learning_rate': 0.3, 'boosting_type': 'gbdt'}. Best is trial 1 with value: 0.9858651252315414.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:18:12,388]\u001b[0m Trial 2 finished with value: 0.979679374974005 and parameters: {'num_leaves': 49, 'n_estimators': 430, 'learning_rate': 0.2, 'boosting_type': 'goss'}. Best is trial 1 with value: 0.9858651252315414.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:25:01,693]\u001b[0m Trial 3 finished with value: 0.5716997476939201 and parameters: {'num_leaves': 44, 'n_estimators': 570, 'learning_rate': 0.7500000000000001, 'boosting_type': 'goss'}. Best is trial 1 with value: 0.9858651252315414.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:26:33,991]\u001b[0m Trial 4 finished with value: 0.9878691844598348 and parameters: {'num_leaves': 50, 'n_estimators': 590, 'learning_rate': 0.45, 'boosting_type': 'gbdt'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:28:05,862]\u001b[0m Trial 5 finished with value: 0.9827607620860498 and parameters: {'num_leaves': 50, 'n_estimators': 500, 'learning_rate': 0.15000000000000002, 'boosting_type': 'gbdt'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:28:09,910]\u001b[0m Trial 6 failed, because the objective function returned nan.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:39:17,722]\u001b[0m Trial 7 finished with value: 0.9846700909173325 and parameters: {'num_leaves': 49, 'n_estimators': 550, 'learning_rate': 0.6500000000000001, 'boosting_type': 'dart'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:47:23,276]\u001b[0m Trial 8 finished with value: 0.9820015728670708 and parameters: {'num_leaves': 32, 'n_estimators': 550, 'learning_rate': 0.6500000000000001, 'boosting_type': 'dart'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:48:41,086]\u001b[0m Trial 9 finished with value: 0.9868011921163994 and parameters: {'num_leaves': 49, 'n_estimators': 430, 'learning_rate': 0.45, 'boosting_type': 'gbdt'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "\u001b[32m[I 2022-06-22 18:55:02,417]\u001b[0m Trial 10 finished with value: 0.9305399175337514 and parameters: {'num_leaves': 44, 'n_estimators': 410, 'learning_rate': 0.1, 'boosting_type': 'dart'}. Best is trial 4 with value: 0.9878691844598348.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:06,831]\u001b[0m Trial 11 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:11,064]\u001b[0m Trial 12 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:15,085]\u001b[0m Trial 13 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:19,418]\u001b[0m Trial 14 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:23,481]\u001b[0m Trial 15 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:27,443]\u001b[0m Trial 16 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:31,795]\u001b[0m Trial 17 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:35,735]\u001b[0m Trial 18 failed, because the objective function returned nan.\u001b[0m\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[LightGBM] [Fatal] Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/lightgbm/basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at /Users/runner/miniforge3/conda-bld/lightgbm_1641600054035/work/compile/src/boosting/rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "\u001b[33m[W 2022-06-22 18:55:39,855]\u001b[0m Trial 19 failed, because the objective function returned nan.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest params:\n",
      "\t\tnum_leaves: 50\n",
      "\t\tn_estimators: 590\n",
      "\t\tlearning_rate: 0.45\n",
      "\t\tboosting_type: gbdt\n",
      "CPU times: user 5h 45s, sys: 15min 12s, total: 5h 15min 58s\n",
      "Wall time: 44min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr_study = optuna_search(objective_lr_lgbm, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30e1ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.76\n"
     ]
    }
   ],
   "source": [
    "score_check(LGBMClassifier(num_leaves = 50, n_estimators = 590, learning_rate = .45, boosting_type = 'gbdt'))      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f4853",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "\n",
    "По итогам данного раздела наилучший результат достиг значения метрики f1 в 0.76. При этом пороговые значения преодолевают три модели, однако из-за очень долгой работы модели CatBoost на тестовой выборке будут проверены две: LGBM и логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f990e",
   "metadata": {},
   "source": [
    "Полученный результат показывает, содержательность изучения моделей машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a5287",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что попробовал разные модели в этом шаге!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acc84b",
   "metadata": {},
   "source": [
    "# Шаг. Проверка моделей.\n",
    "\n",
    "## Проверка лучших моделей на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "118b359b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.77\n"
     ]
    }
   ],
   "source": [
    "score_check(LGBMClassifier(num_leaves = 51, n_estimators = 370, learning_rate = .65000000000000001, boosting_type = 'gbdt', random_state= RND),\n",
    "            X = vect_train_cv_upsampled, \n",
    "            y = target_train_upsampled, \n",
    "            z = vect_test_cv_up,\n",
    "            zt = target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32f5fa14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maksimkeller/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "score_check(LogisticRegression(),\n",
    "            X = vect_train_cv_upsampled, \n",
    "            y = target_train_upsampled, \n",
    "            z = vect_test_cv_up,\n",
    "            zt = target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07a5cf",
   "metadata": {},
   "source": [
    "Полученные значения говорят, что обе модели удовлтетворяют цели, поставленной в данном исследовании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f856a5b6",
   "metadata": {},
   "source": [
    "## Проверка на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d8e8f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 метрика: 0.19\n"
     ]
    }
   ],
   "source": [
    "score_check(DummyClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7155b5",
   "metadata": {},
   "source": [
    "Полученное значение позволяет утверждать, что построенная модель, способна достаточно точно определять токсичные комментарии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f67f67",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Тестирование было сделано верно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70c95a",
   "metadata": {},
   "source": [
    "# Шаг. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70918c28",
   "metadata": {},
   "source": [
    "В данном исследовании для интернет-магазина «Викишоп» была построена модель, способная клиссифицировать комментарии на позитивные и негативные с метрикой качества f1 не меньше 0.75. \n",
    "\n",
    "По итогу выполнения поставленной цели было построено две модели, способные классифицировать комментарии с значением метрики f1 превышающим пороговые значения, что было проверено на двух независимых выборках.\n",
    "Отдельно была проведена проверка на \"адекватность\", которая показала, что построенные модели способны достаточно эффективно определять токсичные комментарии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4730fe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Хорошо, что проект заканчивается выводом!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
